{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "county_ba = pd.read_csv('../../../data/county_to_ba.csv')\n",
    "ba_to_state = pd.read_csv('../../../data/ba_to_state.csv')\n",
    "aeo_2023 = pd.read_csv('../../../data/demand_AEO_2023_reference.csv')\n",
    "county_map = pd.read_csv('../../../data/dgen_county_fips_mapping.csv')\n",
    "load_growth = pd.read_csv('../../../data/load_growth_to_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust county_ba for one PA county\n",
    "county_ba['ba'] = np.where(\n",
    "    (county_ba['ba'] == 'p119') | (county_ba['ba'] == 'p122'),\n",
    "    'p115',\n",
    "    county_ba['ba']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First extract unique combinations from balance area to state mapping\n",
    "ba_to_state_unique = ba_to_state[['ba', 'state']].drop_duplicates(subset=['ba', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-base AEO 2023 data to 2026\n",
    "\n",
    "# Get the 2026 multiplier per state\n",
    "base_multipliers = aeo_2023[aeo_2023['year'] == 2026][['state', 'multiplier']].rename(columns={'multiplier': 'base_multiplier'})\n",
    "\n",
    "# Merge with the original DataFrame\n",
    "aeo_2023 = aeo_2023.merge(base_multipliers, on='state', how='left')\n",
    "\n",
    "# Rebase the multiplier\n",
    "aeo_2023['multiplier'] = aeo_2023['multiplier'] / aeo_2023['base_multiplier']\n",
    "\n",
    "# Only years after 2025\n",
    "aeo_2023 = aeo_2023[aeo_2023['year'] > 2025]\n",
    "\n",
    "# Join load growth data with ba_to_state_unique to get ba associated with load growth multipliers\n",
    "aeo_2023_ba = aeo_2023.merge(ba_to_state_unique, on='state', how='inner')\n",
    "\n",
    "# Add sector\n",
    "aeo_2023_ba['sector_abbr'] = 'res'\n",
    "aeo_2023_ba['load_growth_scenario_2023'] = 'AEO2023 Reference'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join aeo data with county_ba mapping to get load growth multipliers for each county\n",
    "aeo_2023_county = aeo_2023_ba.merge(county_ba, on='ba', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join aeo data to NERC regions and format eventual df for export\n",
    "load_growth = (\n",
    "    load_growth[['year', 'sector_abbr', 'county_id', 'nerc_region_desc', 'nerc_region_abbr', 'load_multiplier', 'load_growth_scenario']][load_growth['year'] > 2025]\n",
    "    .merge(aeo_2023_county[['county_id', 'year', 'sector_abbr', 'multiplier', 'load_growth_scenario_2023']], on=['county_id', 'year', 'sector_abbr'], how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute 2023-based load multipliers for residential sector\n",
    "load_growth['load_multiplier'] = np.where(load_growth['sector_abbr'] == 'res', load_growth['multiplier'], load_growth['load_multiplier'])\n",
    "load_growth['load_growth_scenario'] = np.where(load_growth['sector_abbr'] == 'res', load_growth['load_growth_scenario_2023'], load_growth['load_growth_scenario'])\n",
    "\n",
    "# Ensure dtypes are correct\n",
    "load_growth['load_multiplier'] = load_growth['load_multiplier'].astype(float)\n",
    "\n",
    "# Subset to appropriate columns\n",
    "load_growth_adjusted = load_growth[['year', 'sector_abbr', 'county_id', 'nerc_region_desc', 'nerc_region_abbr', 'load_growth_scenario', 'load_multiplier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the load growth file\n",
    "load_growth_adjusted.to_csv('../../../data/load_growth_to_model_adjusted.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace table locally\n",
    "\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASS = \"postgres\"\n",
    "DB_NAME = \"dgen_db\"\n",
    "DB_PORT = 5432\n",
    "DB_HOST = \"localhost\"  # or 127.0.0.1 if using proxy\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    ")\n",
    "\n",
    "TBL_SCHEMA   = \"diffusion_shared\"\n",
    "VIEW_SCHEMA  = \"diffusion_template\"\n",
    "TABLE_NAME   = \"load_growth_to_model_adjusted\"\n",
    "VIEW_NAME    = \"load_growth_to_model\"\n",
    "\n",
    "def _type_sql(r):\n",
    "    dt = r[\"data_type\"]\n",
    "    if dt == \"character varying\":\n",
    "        l = r[\"character_maximum_length\"]\n",
    "        return f\"varchar({l})\" if l else \"varchar\"\n",
    "    if dt == \"character\":\n",
    "        l = r[\"character_maximum_length\"]\n",
    "        return f\"char({l})\" if l else \"char\"\n",
    "    if dt == \"numeric\":\n",
    "        p, s = r[\"numeric_precision\"], r[\"numeric_scale\"]\n",
    "        return f\"numeric({p},{s})\" if p and s is not None else \"numeric\"\n",
    "    if dt in (\"double precision\", \"integer\", \"bigint\", \"real\", \"boolean\", \"text\"):\n",
    "        return dt\n",
    "    return r[\"udt_name\"]\n",
    "\n",
    "with engine.begin() as con:\n",
    "    # Ensure schemas\n",
    "    con.exec_driver_sql(f\"CREATE SCHEMA IF NOT EXISTS {TBL_SCHEMA};\")\n",
    "    con.exec_driver_sql(f\"CREATE SCHEMA IF NOT EXISTS {VIEW_SCHEMA};\")\n",
    "\n",
    "    # Ensure table exists in diffusion_shared, then refresh contents\n",
    "    load_growth.head(0).to_sql(TABLE_NAME, con=con, schema=TBL_SCHEMA, if_exists=\"append\", index=False)\n",
    "    con.exec_driver_sql(f\"TRUNCATE {TBL_SCHEMA}.{TABLE_NAME};\")\n",
    "    load_growth_adjusted.to_sql(TABLE_NAME, con=con, schema=TBL_SCHEMA, if_exists=\"append\", index=False)\n",
    "\n",
    "    # If the view already exists, preserve its column types; else create a simple one\n",
    "    rows = con.execute(\n",
    "        text(\"\"\"\n",
    "            SELECT column_name, data_type, character_maximum_length,\n",
    "                   numeric_precision, numeric_scale, udt_name\n",
    "            FROM information_schema.columns\n",
    "            WHERE table_schema = :schema AND table_name = :view\n",
    "            ORDER BY ordinal_position\n",
    "        \"\"\"),\n",
    "        {\"schema\": VIEW_SCHEMA, \"view\": VIEW_NAME},\n",
    "    ).mappings().all()\n",
    "\n",
    "    if rows:\n",
    "        cast_selects = \", \".join(\n",
    "            f\"CAST({r['column_name']} AS {_type_sql(r)}) AS {r['column_name']}\"\n",
    "            for r in rows\n",
    "        )\n",
    "        con.exec_driver_sql(f\"\"\"\n",
    "            CREATE OR REPLACE VIEW {VIEW_SCHEMA}.{VIEW_NAME} AS\n",
    "            SELECT {cast_selects}\n",
    "            FROM {TBL_SCHEMA}.{TABLE_NAME};\n",
    "        \"\"\")\n",
    "    else:\n",
    "        # first creation: define the canonical order explicitly\n",
    "        con.exec_driver_sql(f\"\"\"\n",
    "            CREATE OR REPLACE VIEW {VIEW_SCHEMA}.{VIEW_NAME} AS\n",
    "            SELECT\n",
    "              year,\n",
    "              sector_abbr,\n",
    "              county_id,\n",
    "              nerc_region_desc,\n",
    "              nerc_region_abbr,\n",
    "              load_growth_scenario,\n",
    "              load_multiplier\n",
    "            FROM {TBL_SCHEMA}.{TABLE_NAME};\n",
    "        \"\"\")\n",
    "\n",
    "engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DB config ---\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASS = \"postgres\"\n",
    "DB_NAME = \"dgendb\"\n",
    "DB_PORT = 5432\n",
    "DB_HOST = \"127.0.0.1\"  # Cloud SQL Proxy\n",
    "conn_str = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# --- Object names ---\n",
    "TABLE_NAME   = \"load_growth_to_model_adjusted\"   # base table\n",
    "VIEW_NAME    = \"load_growth_to_model\"            # view\n",
    "VIEW_SCHEMA  = \"diffusion_template\"\n",
    "TABLE_SCHEMA = \"diffusion_shared\"\n",
    "\n",
    "def _type_sql(r):\n",
    "    dt = r[\"data_type\"]\n",
    "    if dt == \"character varying\":\n",
    "        l = r[\"character_maximum_length\"]; return f\"varchar({l})\" if l else \"varchar\"\n",
    "    if dt == \"character\":\n",
    "        l = r[\"character_maximum_length\"]; return f\"char({l})\" if l else \"char\"\n",
    "    if dt == \"numeric\":\n",
    "        p, s = r[\"numeric_precision\"], r[\"numeric_scale\"]\n",
    "        return f\"numeric({p},{s})\" if p and s is not None else \"numeric\"\n",
    "    if dt in (\n",
    "        \"double precision\", \"integer\", \"bigint\", \"real\", \"boolean\", \"text\",\n",
    "        \"date\", \"timestamp without time zone\", \"timestamp with time zone\"\n",
    "    ):\n",
    "        return dt\n",
    "    return r[\"udt_name\"]  # fallback\n",
    "\n",
    "with engine.begin() as con:\n",
    "    # Ensure schemas exist\n",
    "    con.execute(text(f'CREATE SCHEMA IF NOT EXISTS {TABLE_SCHEMA};'))\n",
    "    con.execute(text(f'CREATE SCHEMA IF NOT EXISTS {VIEW_SCHEMA};'))\n",
    "\n",
    "    # Does the base table already exist?\n",
    "    table_exists = con.execute(\n",
    "        text(\"\"\"\n",
    "            SELECT EXISTS (\n",
    "              SELECT 1\n",
    "              FROM information_schema.tables\n",
    "              WHERE table_schema = :schema AND table_name = :table\n",
    "            )\n",
    "        \"\"\"),\n",
    "        {\"schema\": TABLE_SCHEMA, \"table\": TABLE_NAME},\n",
    "    ).scalar()\n",
    "\n",
    "    if table_exists:\n",
    "        # Keep structure + deps; just replace rows\n",
    "        con.execute(text(f'TRUNCATE {TABLE_SCHEMA}.{TABLE_NAME};'))\n",
    "        load_growth_adjusted.to_sql(\n",
    "            TABLE_NAME, con=con, schema=TABLE_SCHEMA,\n",
    "            if_exists=\"append\", index=False, method=\"multi\"\n",
    "        )\n",
    "    else:\n",
    "        # First time: create table from DataFrame\n",
    "        load_growth_adjusted.to_sql(\n",
    "            TABLE_NAME, con=con, schema=TABLE_SCHEMA,\n",
    "            if_exists=\"replace\", index=False, method=\"multi\"\n",
    "        )\n",
    "\n",
    "    # Get current view column spec (if the view already exists)\n",
    "    view_cols = con.execute(\n",
    "        text(\"\"\"\n",
    "            SELECT column_name, data_type, character_maximum_length,\n",
    "                   numeric_precision, numeric_scale, udt_name\n",
    "            FROM information_schema.columns\n",
    "            WHERE table_schema = :schema AND table_name = :view\n",
    "            ORDER BY ordinal_position\n",
    "        \"\"\"),\n",
    "        {\"schema\": VIEW_SCHEMA, \"view\": VIEW_NAME},\n",
    "    ).mappings().all()\n",
    "\n",
    "    if view_cols:\n",
    "        # Preserve existing view column order & types\n",
    "        cast_selects = \", \".join(\n",
    "            f'CAST(\"{c[\"column_name\"]}\" AS {_type_sql(c)}) AS \"{c[\"column_name\"]}\"'\n",
    "            for c in view_cols\n",
    "        )\n",
    "        con.execute(text(f\"\"\"\n",
    "            CREATE OR REPLACE VIEW {VIEW_SCHEMA}.{VIEW_NAME} AS\n",
    "            SELECT {cast_selects}\n",
    "            FROM {TABLE_SCHEMA}.{TABLE_NAME};\n",
    "        \"\"\"))\n",
    "    else:\n",
    "        # First-time view: derive order from the *table* (or use your canonical list)\n",
    "        table_cols = con.execute(\n",
    "            text(\"\"\"\n",
    "                SELECT column_name, data_type, character_maximum_length,\n",
    "                       numeric_precision, numeric_scale, udt_name, ordinal_position\n",
    "                FROM information_schema.columns\n",
    "                WHERE table_schema = :schema AND table_name = :table\n",
    "                ORDER BY ordinal_position\n",
    "            \"\"\"),\n",
    "            {\"schema\": TABLE_SCHEMA, \"table\": TABLE_NAME},\n",
    "        ).mappings().all()\n",
    "\n",
    "        # Preferred order if you want to enforce specific columns:\n",
    "        preferred = [\n",
    "            \"year\", \"sector_abbr\", \"county_id\",\n",
    "            \"nerc_region_desc\", \"nerc_region_abbr\",\n",
    "            \"load_growth_scenario\", \"load_multiplier\",\n",
    "        ]\n",
    "\n",
    "        # Use preferred order where available, then append any remaining columns in table order\n",
    "        table_order = [r[\"column_name\"] for r in table_cols]\n",
    "        ordered = [c for c in preferred if c in table_order] + [c for c in table_order if c not in preferred]\n",
    "\n",
    "        type_map = {r[\"column_name\"]: _type_sql(r) for r in table_cols}\n",
    "        cast_selects = \", \".join(\n",
    "            f'CAST(\"{c}\" AS {type_map.get(c, \"text\")}) AS \"{c}\"' for c in ordered\n",
    "        )\n",
    "\n",
    "        con.execute(text(f\"\"\"\n",
    "            CREATE OR REPLACE VIEW {VIEW_SCHEMA}.{VIEW_NAME} AS\n",
    "            SELECT {cast_selects}\n",
    "            FROM {TABLE_SCHEMA}.{TABLE_NAME};\n",
    "        \"\"\"))\n",
    "\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dg3n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
