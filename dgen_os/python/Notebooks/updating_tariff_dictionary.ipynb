{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook will swap in new utility rates pulled by the dGen team and attach them to the existing agent file. It will save the agent file.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing agent file\n",
    "agents = pd.read_pickle(\"../../input_agents/agent_df_base_res_national_load_adjusted.pkl\")\n",
    "rates = pd.read_csv(\"../../../data/residential_agents_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out agent_id column\n",
    "agents = agents.reset_index(drop = False)\n",
    "\n",
    "# Join new rates to agent file\n",
    "agents_rates = agents.drop(\"tariff_dict\", axis = 1).merge(rates[['bldg_id', 'tariff_dict']], on = 'bldg_id').set_index(\"agent_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the .pkl file\n",
    "agents_rates.to_pickle(\"../../input_agents/agent_df_base_res_national_updated_rates.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../input_agents/agent_df_base_res_national_updated_wholesale_prices.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charges = []\n",
    "missing_ids = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        td = row[\"tariff_dict\"]\n",
    "        if isinstance(td, str):\n",
    "            td = ast.literal_eval(td)  # parse string into dict\n",
    "        if \"ur_monthly_fixed_charge\" in td:\n",
    "            charges.append(td[\"ur_monthly_fixed_charge\"])\n",
    "        else:\n",
    "            missing_ids.append(row.get(\"agent_id\", _))\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing tariff_dict for agent {row.get('agent_id', _)}: {e}\")\n",
    "\n",
    "charges = np.array(charges, dtype=object)  # don't coerce yet to keep nans as-is\n",
    "\n",
    "# Unique values (preserves nans if any)\n",
    "unique_vals = pd.Series(charges).drop_duplicates()\n",
    "\n",
    "print(\"=== Unique ur_monthly_fixed_charge values ===\")\n",
    "print(unique_vals)\n",
    "\n",
    "if missing_ids:\n",
    "    print(f\"\\nAgents missing ur_monthly_fixed_charge: {len(missing_ids)}\")\n",
    "    print(missing_ids[:20], \"...\" if len(missing_ids) > 20 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, json, ast, re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, json, ast, re\n",
    "\n",
    "# Load your agents file (adjust as needed)\n",
    "# df = pd.read_parquet(\"dgen_os/input_agents/agents.parquet\")\n",
    "# or:\n",
    "# df = pd.read_csv(\"dgen_os/input_agents/agents.csv\")\n",
    "\n",
    "def try_parse_tariff(raw):\n",
    "    \"\"\"Return (parsed_dict, parse_method). Robust to dict/JSON/literal, tolerates nan/None tokens.\"\"\"\n",
    "    if isinstance(raw, dict):\n",
    "        return raw, \"dict\"\n",
    "    if isinstance(raw, str):\n",
    "        s = re.sub(r'\\bnan\\b', 'null', raw, flags=re.IGNORECASE)\n",
    "        s = re.sub(r'\\bNone\\b', 'null', s)\n",
    "        try:\n",
    "            return json.loads(s), \"json\"\n",
    "        except Exception:\n",
    "            try:\n",
    "                return ast.literal_eval(raw), \"literal\"\n",
    "            except Exception:\n",
    "                return None, \"unparseable\"\n",
    "    return None, type(raw).__name__\n",
    "\n",
    "def classify_schema(td):\n",
    "    \"\"\"Classify by top-level keys.\"\"\"\n",
    "    if not isinstance(td, dict):\n",
    "        return \"NONE\"\n",
    "    ks = set(td.keys())\n",
    "    has_ur = any(k.startswith(\"ur_\") for k in ks)\n",
    "    has_ed = any(k.startswith((\"e_\",\"d_\")) for k in ks)\n",
    "    if has_ur and not has_ed: return \"UR5\"\n",
    "    if has_ed and not has_ur: return \"LEGACY_ED\"\n",
    "    if has_ur and has_ed:     return \"MIXED\"\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "REQUIRED_UR_KEYS = {\n",
    "    \"ur_monthly_fixed_charge\",\n",
    "    \"ur_ec_tou_mat\", \"ur_ec_sched_weekday\", \"ur_ec_sched_weekend\",\n",
    "    \"ur_dc_enable\", \"ur_dc_sched_weekday\", \"ur_dc_sched_weekend\"\n",
    "}\n",
    "\n",
    "def nullish(x):\n",
    "    if x is None: return True\n",
    "    if isinstance(x, str) and x.strip().lower() in (\"\", \"nan\", \"none\", \"null\"): return True\n",
    "    return False\n",
    "\n",
    "def shape_12x24(mat):\n",
    "    try:\n",
    "        return len(mat) == 12 and all(len(r) == 24 for r in mat)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "audit_rows = []\n",
    "for idx, row in df.iterrows():\n",
    "    td, how = try_parse_tariff(row[\"tariff_dict\"])\n",
    "    schema = classify_schema(td)\n",
    "    agent_id = row.get(\"agent_id\", idx)\n",
    "\n",
    "    missing = set()\n",
    "    bad_sched = []\n",
    "    if isinstance(td, dict) and schema in (\"UR5\",\"MIXED\"):\n",
    "        for k in REQUIRED_UR_KEYS:\n",
    "            if k not in td or nullish(td.get(k)):\n",
    "                missing.add(k)\n",
    "        # shallow schedule shape check\n",
    "        if \"ur_ec_sched_weekday\" in td and not shape_12x24(td.get(\"ur_ec_sched_weekday\")):\n",
    "            bad_sched.append(\"ur_ec_sched_weekday\")\n",
    "        if \"ur_ec_sched_weekend\" in td and not shape_12x24(td.get(\"ur_ec_sched_weekend\")):\n",
    "            bad_sched.append(\"ur_ec_sched_weekend\")\n",
    "        if \"ur_dc_sched_weekday\" in td and not shape_12x24(td.get(\"ur_dc_sched_weekday\")):\n",
    "            bad_sched.append(\"ur_dc_sched_weekday\")\n",
    "        if \"ur_dc_sched_weekend\" in td and not shape_12x24(td.get(\"ur_dc_sched_weekend\")):\n",
    "            bad_sched.append(\"ur_dc_sched_weekend\")\n",
    "\n",
    "    audit_rows.append({\n",
    "        \"idx\": idx,\n",
    "        \"agent_id\": agent_id,\n",
    "        \"parse_method\": how,\n",
    "        \"schema\": schema,\n",
    "        \"has_ur_mfc\": isinstance(td, dict) and \"ur_monthly_fixed_charge\" in td,\n",
    "        \"ur_mfc_nullish\": isinstance(td, dict) and nullish(td.get(\"ur_monthly_fixed_charge\")),\n",
    "        \"missing_required_count\": len(missing),\n",
    "        \"missing_required_keys\": sorted(missing)[:6],   # preview first few\n",
    "        \"bad_sched\": bad_sched[:4],                     # preview first few\n",
    "    })\n",
    "\n",
    "audit = pd.DataFrame(audit_rows)\n",
    "\n",
    "# ---- High-level overview ----\n",
    "print(\"=== parse_method counts ===\")\n",
    "print(audit[\"parse_method\"].value_counts(), \"\\n\")\n",
    "\n",
    "print(\"=== schema counts ===\")\n",
    "print(audit[\"schema\"].value_counts(), \"\\n\")\n",
    "\n",
    "print(\"=== rows with unparseable tariff_dict ===\")\n",
    "print(audit[audit[\"parse_method\"]==\"unparseable\"][[\"agent_id\",\"idx\"]].head(20), \"\\n\")\n",
    "\n",
    "print(\"=== rows not in UR5 schema (LEGACY/MIXED/UNKNOWN) ===\")\n",
    "print(audit[audit[\"schema\"]!=\"UR5\"][[\"agent_id\",\"idx\",\"schema\",\"parse_method\"]].head(20), \"\\n\")\n",
    "\n",
    "print(\"=== rows missing any required UR keys ===\")\n",
    "print(audit[audit[\"missing_required_count\"]>0][[\"agent_id\",\"idx\",\"missing_required_keys\"]].head(20), \"\\n\")\n",
    "\n",
    "print(\"=== rows with nullish ur_monthly_fixed_charge ===\")\n",
    "print(audit[audit[\"ur_mfc_nullish\"]][[\"agent_id\",\"idx\"]].head(20), \"\\n\")\n",
    "\n",
    "print(\"=== schedule shape issues (not 12x24) ===\")\n",
    "print(audit[audit[\"bad_sched\"].map(bool)][[\"agent_id\",\"idx\",\"bad_sched\"]].head(20), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['agent_id'] == 486643]['tariff_dict'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dg3n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
