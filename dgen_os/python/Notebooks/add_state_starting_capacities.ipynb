{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "#### Add state starting capacities\n",
    "Update state starting capacities to reflect the current state of solar + storage penetration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from input_data_functions import stacked_sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../../../data/state_starting_capacities_to_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize booleans if they came in as strings\n",
    "df[\"net_metering\"] = (\n",
    "    df[\"net_metering\"]\n",
    "      .replace({\"TRUE\": True, \"FALSE\": False, \"True\": True, \"False\": False})\n",
    "      .astype(\"boolean\")\n",
    ")\n",
    "\n",
    "# Ensure numeric dtypes\n",
    "for col in [\"system_mw\", \"system_mwh\", \"systems_count\"]:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# ---- Enforce MWh logic ----\n",
    "# Make system_mwh null for solar rows\n",
    "is_solar = df[\"tech\"].str.lower().eq(\"solar\")\n",
    "df.loc[is_solar, \"system_mwh\"] = np.nan\n",
    "\n",
    "# For storage rows, ensure system_mwh >= 2 × system_mw\n",
    "is_storage = df[\"tech\"].str.lower().eq(\"storage\")\n",
    "required_mwh = 2.0 * df.loc[is_storage, \"system_mw\"]\n",
    "needs_bump = df.loc[is_storage, \"system_mwh\"].isna() | (\n",
    "    df.loc[is_storage, \"system_mwh\"] < required_mwh\n",
    ")\n",
    "df.loc[is_storage, \"system_mwh\"] = np.where(\n",
    "    needs_bump, required_mwh, df.loc[is_storage, \"system_mwh\"]\n",
    ")\n",
    "\n",
    "# --- 1) ratio (systems per MW) by tech, using only net_metering == True ---\n",
    "true_nm = df[df[\"net_metering\"] == True].copy()\n",
    "\n",
    "ratio_by_tech = (\n",
    "    true_nm.groupby(\"tech\", dropna=False)\n",
    "           .agg(systems_count_sum=(\"systems_count\", \"sum\"),\n",
    "                system_mw_sum=(\"system_mw\", \"sum\"))\n",
    "           .assign(ratio=lambda g: np.where(\n",
    "               g[\"system_mw_sum\"] > 0,\n",
    "               g[\"systems_count_sum\"] / g[\"system_mw_sum\"],\n",
    "               np.nan\n",
    "           ))[\"ratio\"]\n",
    ")\n",
    "# No global fallback — strictly tech-specific\n",
    "\n",
    "# --- 2) fill NA systems_count where net_metering == False using ratio * system_mw ---\n",
    "df_filled = df.copy()\n",
    "mask_fill = (df_filled[\"net_metering\"] == False) & (df_filled[\"systems_count\"].isna())\n",
    "\n",
    "# Map per-tech ratio; rows for techs without a valid ratio will remain NaN\n",
    "tech_ratio = df_filled.loc[mask_fill, \"tech\"].map(ratio_by_tech)\n",
    "df_filled.loc[mask_fill, \"systems_count\"] = (\n",
    "    df_filled.loc[mask_fill, \"system_mw\"] * tech_ratio\n",
    ")\n",
    "\n",
    "# Integer system counts\n",
    "df_filled[\"systems_count\"] = df_filled[\"systems_count\"].round().astype(\"Int64\")\n",
    "\n",
    "# --- 3) aggregate by (tech, sector_abbr, state_abbr), summing metrics ---\n",
    "# Use sum(min_count=1) so solar system_mwh stays NaN (not 0) when all inputs are NaN\n",
    "group_cols = [\"tech\", \"sector_abbr\", \"state_abbr\"]\n",
    "agg = (\n",
    "    df_filled\n",
    "      .groupby(group_cols, as_index=False, dropna=False)\n",
    "      .agg(\n",
    "          system_mw=(\"system_mw\", \"sum\"),\n",
    "          system_mwh=(\"system_mwh\", lambda s: s.sum(min_count=1)),\n",
    "          systems_count=(\"systems_count\", \"sum\"),\n",
    "      )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace starting capacities in cloud sql\n",
    "\n",
    "# Connection config \n",
    "DB_USER = \"postgres\"\n",
    "DB_PASS = \"postgres\"\n",
    "DB_NAME = \"dgendb\"\n",
    "DB_PORT = 5432\n",
    "DB_HOST = \"127.0.0.1\"  # Cloud SQL Proxy\n",
    "conn_str = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "TABLE_NAME = \"state_starting_capacities_to_model_tbl\"\n",
    "VIEW_NAME  = \"state_starting_capacities_to_model\"\n",
    "SCHEMA     = \"diffusion_template\"\n",
    "\n",
    "def _type_sql(r):\n",
    "    dt = r[\"data_type\"]\n",
    "    if dt == \"character varying\":\n",
    "        l = r[\"character_maximum_length\"]\n",
    "        return f\"varchar({l})\" if l else \"varchar\"\n",
    "    if dt == \"character\":\n",
    "        l = r[\"character_maximum_length\"]\n",
    "        return f\"char({l})\" if l else \"char\"\n",
    "    if dt == \"numeric\":\n",
    "        p, s = r[\"numeric_precision\"], r[\"numeric_scale\"]\n",
    "        return f\"numeric({p},{s})\" if p and s is not None else \"numeric\"\n",
    "    if dt in (\"double precision\", \"integer\", \"bigint\", \"real\", \"boolean\", \"text\"):\n",
    "        return dt\n",
    "    # fallback to udt_name if needed\n",
    "    return r[\"udt_name\"]\n",
    "\n",
    "with engine.begin() as con:\n",
    "    # Ensure the table exists, then refresh contents safely\n",
    "    agg.head(0).to_sql(TABLE_NAME, con=con, schema=SCHEMA, if_exists=\"append\", index=False)\n",
    "    con.execute(text(f\"TRUNCATE TABLE {SCHEMA}.{TABLE_NAME};\"))\n",
    "    agg.to_sql(TABLE_NAME, con=con, schema=SCHEMA, if_exists=\"append\", index=False)\n",
    "\n",
    "    # Introspect existing view column types so CREATE OR REPLACE keeps types identical\n",
    "    rows = con.execute(\n",
    "        text(\"\"\"\n",
    "            SELECT column_name, data_type, character_maximum_length,\n",
    "                   numeric_precision, numeric_scale, udt_name\n",
    "            FROM information_schema.columns\n",
    "            WHERE table_schema = :schema AND table_name = :view\n",
    "            ORDER BY ordinal_position\n",
    "        \"\"\"),\n",
    "        {\"schema\": SCHEMA, \"view\": VIEW_NAME},\n",
    "    ).mappings().all()\n",
    "\n",
    "    # Build CAST list that matches the current view's column types\n",
    "    cast_selects = \", \".join(\n",
    "        [f\"CAST({r['column_name']} AS {_type_sql(r)}) AS {r['column_name']}\" for r in rows]\n",
    "    )\n",
    "\n",
    "    # Re-point the view to the table with explicit casts to preserve types\n",
    "    con.execute(text(f\"\"\"\n",
    "        CREATE OR REPLACE VIEW {SCHEMA}.{VIEW_NAME} AS\n",
    "        SELECT {cast_selects}\n",
    "        FROM {SCHEMA}.{TABLE_NAME};\n",
    "    \"\"\"))\n",
    "\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dg3n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
